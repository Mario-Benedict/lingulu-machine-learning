# ğŸ¯ Lingulu â€” Pronunciation Scoring Model (Machine Learning)

This module contains the Machine Learning pipeline used in **Lingulu** to evaluate English pronunciation using speech recognition and phoneme-level scoring.

The model is based on **Wav2Vec2**, fine-tuned for pronunciation assessment using a **phoneme vocabulary** and **GOP (Goodness of Pronunciation) scoring**.

---

## ğŸ¯ Purpose

The goal of this model is **not** to transcribe speech into text, but to:

> Evaluate how accurately a user pronounces words and sentences at the phoneme level.

This enables Lingulu to provide **objective pronunciation feedback** to learners.

---

## ğŸ§  Core Concept

The pipeline works as follows:

1. User speaks a sentence
2. Audio is processed by **fine-tuned Wav2Vec2**
3. Model predicts **phoneme sequence probabilities**
4. GOP score is calculated per phoneme
5. Scores are aggregated into:
   - Phoneme score
   - Word score
   - Sentence pronunciation score
6. Results are sent to backend as evaluation feedback

---

## ğŸ—ï¸ Model Architecture

| Component | Description |
|-----------|-------------|
| Base Model | moxeeeem/wav2vec2-finetuned-pronunciation-correction2 |
| Fine-tuning Target | Phoneme recognition (not text ASR) |
| Vocabulary | Custom phoneme set (ARPAbet/IPA-based) |
| Output | Phoneme probability distribution |
| Scoring Method | GOP (Goodness of Pronunciation) |

---
## ğŸ“‚ Folder Structure
```
lingulu-machine-learning/
â”‚â”€â”€ app/
â”‚â”€â”€ notebooks/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ v1/
|   |   |  â”œâ”€â”€ model_finetune.ipynb
|   |   |  â””â”€â”€ train_history.csv
â”‚   â”‚   â”œâ”€â”€ v2/
|   |   |  â”œâ”€â”€ model_finetune.ipynb
|   |   |  â””â”€â”€ train_history.csv
â”‚   â”‚   â””â”€â”€ v3/
|   |      â”œâ”€â”€ model_finetune.ipynb
|   |      â””â”€â”€ train_history.csv
â”‚   â”œâ”€â”€ audio_converter.ipynb
â”‚   â”œâ”€â”€ dataset_sampling.ipynb
â”‚   â””â”€â”€ model_evaluate_v3.ipynb
â”‚â”€â”€ .gitignore
â””â”€â”€ requirements.txt
```
---
## âš™ï¸ Installation

### Requirements

- Python 3.11+
- PyTorch
- Transformers (HuggingFace)
- Librosa
- NumPy

### Install dependencies:

```bash
pip install -r requirements.txt
```

### Running server 
```bash
python -m app.app
```

## ğŸ§® GOP Scoring

GOP measures how closely a spoken phoneme matches the expected phoneme.

Formula : 

```lua
GOP(p) = log P(p | audio) - max log P(q | audio)
```
Where:
- p = expected phoneme
- q = all possible phonemes

Higher GOP = better pronunciation.

---
## ğŸ”— Integration with Backend

Input:

- Audio file from user

- Expected sentence

Output (JSON):

```json
{
    "audio_duration_seconds": 1.28,
    "audio_samples": 20480,
    "filename": "He is a teacher.mp3",
    "latency_seconds": 0.29187,
    "pronounciation_assessment": {
        "average_score": 57.7,
        "gop_latency_seconds": 0.19755,
        "text": "He is a teacher",
        "words": [
            {
                "phonemes": [
                    {
                        "phoneme": "h",
                        "score": 89.2
                    },
                    {
                        "phoneme": "i",
                        "score": 73.2
                    }
                ],
                "score": 81.2,
                "word": "He"
            },
            {
                "phonemes": [
                    {
                        "phoneme": "Éª",
                        "score": 78.9
                    },
                    {
                        "phoneme": "z",
                        "score": 83.1
                    }
                ],
                "score": 81.0,
                "word": "is"
            },
            {
                "phonemes": [
                    {
                        "phoneme": "É™",
                        "score": 0.0
                    }
                ],
                "score": 0.0,
                "word": "a"
            },
            {
                "phonemes": [
                    {
                        "phoneme": "t",
                        "score": 100.0
                    },
                    {
                        "phoneme": "i",
                        "score": 95.5
                    },
                    {
                        "phoneme": "tÊƒ",
                        "score": 78.2
                    },
                    {
                        "phoneme": "Éš",
                        "score": 0.0
                    }
                ],
                "score": 68.4,
                "word": "teacher"
            }
        ]
    },
    "reference_text": "He is a teacher",
    "status": "success",
    "transcription": "hiÉªzÊŒtitÊƒÉš"
}
```

---

## ğŸ“Š Why Wav2Vec2?

Wav2Vec2 is used because:

- Strong representation of speech features

- Works well with limited labeled data

- Suitable for phoneme-level tasks

- State-of-the-art for speech understanding

---

## ğŸš€ Deployment

This API is deployed to **Google Cloud Run** in **Singapore region** (`asia-southeast1`) with **L4 GPU** for optimal performance.

### Architecture

- **Platform**: Google Cloud Run (Serverless container deployment)
- **Region**: Singapore (asia-southeast1) - GPU support available
- **GPU**: NVIDIA L4 (24GB VRAM) - **Required for best performance**
- **Container**: Docker with NVIDIA CUDA 12.1 runtime
- **Scaling**: Auto-scale 0â†’N instances based on traffic
- **Cost**: Pay-per-use (no charge when idle)

### âš¡ GPU Performance

**This project REQUIRES GPU for optimal performance:**

| Metric | CPU Only | **L4 GPU** | Improvement |
|--------|----------|------------|-------------|
| Inference Time | ~800ms | **~150ms** | ğŸš€ **5.3x faster** |
| Throughput | ~7 req/s | **~40 req/s** | ğŸ“ˆ **5.7x higher** |
| User Experience | Slow | **Fast** | â­ **Production-ready** |

**Recommended**: Deploy with **nvidia-l4** GPU for best price/performance ratio.

### Quick Deploy via GitHub Actions

The repository is configured with CI/CD pipeline:

1. **Push to `main` branch** â†’ Automatically triggers:
   - CI: Run tests and validation
   - CD: Build Docker image â†’ Push to Artifact Registry â†’ Deploy to Cloud Run

2. **Manual Deploy**: 
   - Go to **Actions** tab â†’ Select "CD - Deploy to Google Cloud Run" â†’ Click "Run workflow"

### API Endpoints

Once deployed, the API is accessible at your Cloud Run service URL:

```
https://lingulu-ml-api-XXXXXX-as.a.run.app
```

**Available Endpoints:**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/model/health` | GET | Health check |
| `/api/model/predict` | POST | Pronunciation assessment |
| `/api/metrics` | GET | Performance metrics (p50, p90, p99) |

### Example Usage

```bash
# Health check
curl https://YOUR-SERVICE-URL/api/model/health

# Pronunciation assessment
curl -X POST https://YOUR-SERVICE-URL/api/model/predict \
  -F "file=@audio.wav" \
  -F "text=Hello world"
```

### Configuration

Environment variables are injected at deployment via Cloud Run configuration:

| Variable | Description | Default |
|----------|-------------|---------|
| `MODEL_ID` | HuggingFace model ID | `marx90/lingulu_wav2vec2_pronounciation_finetune` |
| `SAMPLING_RATE` | Audio sampling rate | `16000` |
| `MAX_AUDIO_LENGTH_SECONDS` | Max audio duration | `60` |
| `MAX_FILE_SIZE_MB` | Max upload size | `10` |
| `LOG_LEVEL` | Logging level | `INFO` |

### Local Testing

**CPU-only (slower):**
```bash
docker-compose up --build
```

**With GPU (requires NVIDIA Docker runtime):**
```bash
# Ensure nvidia-docker is installed
docker-compose up --build

# Verify GPU is detected
docker exec -it lingulu-ml-app nvidia-smi
```

API will be available at `http://localhost:5000`

```bash
curl http://localhost:5000/api/model/health
```

### Full Documentation

For detailed deployment instructions, environment setup, monitoring, and troubleshooting:

ğŸ“– **See [DEPLOYMENT.md](./DEPLOYMENT.md)** for complete guide

---

## ğŸŒŸ Future Improvements

- Support IPA phoneme set

- Noise-robust training

- Real-time scoring

- Accent adaptation

---

Made with love â¤ï¸, lack of sleep ğŸ¥± and tears ğŸ’§ by MACAN MULAZ ğŸ…
